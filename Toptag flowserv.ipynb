{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowserv.client import Flowserv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Flowserv(basedir='.flowserv', open_access=True, clear=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowserv.client import FlowservRepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helloworld\tHello World Demo\n",
      "toptagger\tTop Tagger Demo - ML4Jets\n",
      "piesingle\tAnalyze single colony image using PIE\n"
     ]
    }
   ],
   "source": [
    "for template_id, description, _ in FlowservRepo().list():\n",
    "    print('{}\\t{}'.format(template_id, description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installed workflow with id b68937fb353d452586a1ff8f2d8602ee\n"
     ]
    }
   ],
   "source": [
    "workflow_id = client.install('toptagger', ignore_postproc=True)\n",
    "print('installed workflow with id {}'.format(workflow_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Tagger Demo - ML4Jets (1)\n",
      "\n",
      "ROB Demo for the Machine Learning Landscape of Top Taggers Comparison\n",
      "\n",
      "### Benchmark Goals\n",
      "\n",
      "Based on the established task of identifying boosted, hadronically decaying top quarks, this benchmark compares a wide range of modern machine learning approaches (see [The Machine Learning Landscape of Top Taggers](https://arxiv.org/abs/1902.09914) paper for more details).\n",
      "\n",
      "The goal of this study is to see how well different neutral network setups can classify jets based on calorimeter information. While initially it was not clear if any of the machine learning methods applied to toptagging would be able to significantly exceed the performance of the multi-variate tools,later studies have consistently showed that we can expect great performance improvement from most modern tools. This turns around the question into which of the tagging approaches have the best performance (also relative to their training effort), and if the leading taggers make use of the same, hence complete set of information.\n",
      "\n",
      "### How to Participate\n",
      "\n",
      "The benchmark workflow consists of three main steps.\n",
      "\n",
      "![Benchmark Workflow Overview](https://github.com/scailfin/rob-demo-top-tagger/raw/master/docs/graphics/toptagger-overview-small.png \"Top Tagger Benchmark - Workflow Overview\")\n",
      "\n",
      "Participants are given a test dataset consisting of 200k signal and 200k background jets. The top signal and mixed quark-gluon background jets are produced with using Pythia8 with its default tune for a center-of-mass energy of 14 TeV and ignoring multiple interactions and pile-up. For a simplified detector simulation we use Delphes with the default ATLAS detector card.\n",
      "\n",
      "The produced results should contain classification results for each jet to measure the performance of the network and test which jets are correctly classified in each approach. Overall results are sorted in decreasing order by the background rejection as signal efficiency at 50%.\n"
     ]
    }
   ],
   "source": [
    "workflow = client.open(workflow_id)\n",
    "\n",
    "print(workflow.name())\n",
    "print()\n",
    "print(workflow.description())\n",
    "print()\n",
    "print(workflow.instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict({\n",
    "    'env_preproc': 'heikomueller/toptaggerdemo:1.1',\n",
    "    'cmd_preproc': 'python code/preprocess-dataset.py data/test_jets.pkl data/preprocess/results/',\n",
    "    'env_eval': 'heikomueller/toptaggerdemo:1.1',\n",
    "    'cmd_eval': 'pythond code/TreeNin.py results/processed_test_jets.pkl data/evaluate/results'})\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = workflow.start_run(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in run.files():\n",
    "    print(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
